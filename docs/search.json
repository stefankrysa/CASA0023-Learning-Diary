[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023-Learning-Diary",
    "section": "",
    "text": "Welcome",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Getting started with remote sensing",
    "section": "",
    "text": "1.1 Summary\nThis week, we got started learning about the basics of remote sensing and earth observation. This started with an overview of how sensors collect data. Satellites can detect electromagnetic waves passively or actively, whereby data is either reflected off an object by the sun’s light or a sensor produces its own energy source for illumination, respectively. We learned the fundamentals of EMR, such as identifying wavelength or amplitude, and the range of the electromagnetic spectrum, as depicted in Figure 1. When EMR interacts with a surface, what is reflected is often modified due to energy being absorbed, transmitted through, or scattered. This allows for the detection of spectral signatures, which are unique patterns of reflected or emitted electromagnetic radiation that specific materials exhibit. We also touched on important concepts of spatial, spectral, temporal, and radiometric resolution, which define the characteristics and quality of remotely sensed data.\nIn the practical, we took a closer look at working with Sentinel-2 and Landsat data in SNAP. We started by loading and merging different bands to play around with how they combined to create composite images. True-colour composites create an image that replicate natural colours familiar to humans, while false-colour composites utilize combinations of non-visible bands, such as near-infrared, along with visible bands, to highlight specific features or phenomena, like vegetation. We moved on to compute the tasselled cap transformation in order identify areas of brightness, greenness and wetness, a method particularly useful for identifying urban land use. Then, to classify different land use areas, we selected and exported pixels covering a variety of land covers. Upon loading this data into R, plotting the difference in pixel values across bands highlighted the unique spectral signatures of various land types.\nGiven that Sentinel data typically has a lower spatial and temporal resolution compared to Landsat, I am curious about why researchers would continue to opt for using Landsat data. Since Landsat has been in operation for longer than Sentinel, Landsat provides a longer time range of data, which could be useful for certain research questions. Still, I wonder about any other upsides to using data from one satellite over the other.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "intro.html#summary",
    "href": "intro.html#summary",
    "title": "1  Getting started with remote sensing",
    "section": "",
    "text": "Figure 1. Electromagnetic Spectrum. Source: https://upload.wikimedia.org/wikipedia/commons/c/cf/EM_Spectrum_Properties_edit.svg",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "intro.html#applications",
    "href": "intro.html#applications",
    "title": "1  Getting started with remote sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nSince getting familiar with Landsat and Sentinel imagery formed a major component of the practical, I was curious to find existing research using these sources. I found Landsat and Sentinel imagery serve as valuable resources for monitoring environmental and land use.\n\n1.2.1 Sentinel research\nResearch by Farhadi et al. (2025) was one paper that stood out to me. In this work, the authors use Sentinel imagery at a 10m resolution to build a new spectral index for flood mapping. Specifically, the method utilizes visible and NIR bands to discriminate water characteristics. This new technique, they posit, provides a more efficient method for monitoring flood zones without reliance on thresholding methods, whereby different selections can significantly change results. An index accuracy of above 97% for pre-flood, flooded, and post-flood extraction on two test areas are promising results for their proposed method. Successfully developing this method would not have been possible if not for the high spatial resolution of Sentinel imagery.\n\n\n1.2.2 Landsat research\nWork by Hillson et al. (2019), meanwhile, relies on Landsat imagery. In their research, they aim to estimate population density using a regression model with covariates derived from Landsat imagery of Bo, Sierre Leone. Analysis began with 379 Landsat 5 thematic mapper candidate covariates before narrowing down the selection to six for the final model. Covariates encompass a range of data from Landsat, which include pixel values and a variety of transformations of these values. The final model was found to be effective for predicting population density. This was true at even at a 30m spatial resolution. The authors highlight the utility of such a method to estimate local populations in environments where census data is old or unreliable.\n\n\n1.2.3 Thoughts\nWhile both works provided an interesting showcase of the practical applications of earth observation in different settings, as someone new to this field it was interesting for me to see how the researchers communicated their findings differently. I found the analysis done by Farhadi et al. (2025) to be far simpler to follow than that of Hillson et al. (2019). To me, the former did a better job of outlining their methods in an easy-to-understand way. Perhaps more complex papers will make more sense later in this course, but I also think this points to an important issue in remote sensing research: how to make the work accessible and easy to understand for the general public. As this field gains traction and recognition among policy-makers, it is increasingly important to communicate research in a way that is accessible to all, not just academics.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "intro.html#reflection",
    "href": "intro.html#reflection",
    "title": "1  Getting started with remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nIn the context of climate change and rapid urbanization across the globe, earth observation presents fascinating opportunities to better understand and respond to environmental and land use change.\nSentinel imagery, given at a high spatial and temporal resolution, allows researchers to frequently monitor less-accessible areas with great accuracy. This capability can be leveraged both proactively, by assessing risks and guiding the development of preventative infrastructure, and reactively, by coordinating emergency responses following extreme weather events. Such applications are critical for effectively targeting aid and implementing mitigation strategies to enhance resilience against future events. As we have seen, highly effective methods for monitoring flood zones have already been developed.\nWe also saw the uses of earth observation for urban environments. Monitoring land use and change is valuable to understanding settlement and urban growth patterns and can be employed to make better-informed planning decisions for sustainable growth. Landsat, in operation for over 40 years now, provides a huge range of data for a long period of time. This could be particularly useful in studies analyzing land use change over time.\nIt was interesting to think about how the tools we employed in the practical this week are applicable in a broader context to monitoring landscapes inside and out of cities. Through techniques such as land classification it is possible to conduct analyses of land use and cover applicable to the issues outlined above. This practical was also a humbling reminder of the value of user-friendly software. By running into a handful of issues using SNAP, I was reminded not to take for granted the flexibility inherent to tools like R.\n\n\n\n\nFarhadi, Hadi, Hamid Ebadi, Abbas Kiani, and Ali Asgary. 2025. “Introducing a New Index for Flood Mapping Using Sentinel-2 Imagery (SFMI).” Computers & Geosciences 194 (January): 105742. https://doi.org/10.1016/j.cageo.2024.105742.\n\n\nHillson, Roger, Austin Coates, Joel D. Alejandre, Kathryn H. Jacobsen, Rashid Ansumana, Alfred S. Bockarie, Umaru Bangura, Joseph M. Lamin, and David A. Stenger. 2019. “Estimating the Size of Urban Populations Using Landsat Images: A Case Study of Bo, Sierra Leone, West Africa.” International Journal of Health Geographics 18 (1): 16. https://doi.org/10.1186/s12942-019-0180-1.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Presentation",
    "section": "",
    "text": "xqx results='asis', echo=FALSE} xaringanExtra::embed_xaringan(url = \"https://stefankrysa.github.io/CASA0023-Xaringan-Presentation/\", ratio = \"16:9\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Presentation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Farhadi, Hadi, Hamid Ebadi, Abbas Kiani, and Ali Asgary. 2025.\n“Introducing a New Index for Flood Mapping Using Sentinel-2\nImagery (SFMI).” Computers & Geosciences 194\n(January): 105742. https://doi.org/10.1016/j.cageo.2024.105742.\n\n\nHillson, Roger, Austin Coates, Joel D. Alejandre, Kathryn H. Jacobsen,\nRashid Ansumana, Alfred S. Bockarie, Umaru Bangura, Joseph M. Lamin, and\nDavid A. Stenger. 2019. “Estimating the Size of Urban Populations\nUsing Landsat Images: A Case Study of Bo, Sierra Leone, West\nAfrica.” International Journal of Health Geographics 18\n(1): 16. https://doi.org/10.1186/s12942-019-0180-1.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Policy",
    "section": "",
    "text": "4.1 Summary\nThe London Plan 2021 (Authority 2021) was developed by the Greater London Authority and acts as a framework to guide the spatial development of the Greater London Area over the next 25 or so years. All development decisions following the adaptation of the Plan in 2021 should, in theory, adhere to the policies outlined in the document. The Plan covers a range of topics and issues, organized into categories of Good Growth, Spatial Development Patterns, Design, Housing, Social Infrastructure, Economy, Heritage and Culture, Green Infrastructure and Natural Environment, Sustainable Infrastructure and, finally, Transport.\nMy policy of focus is G1 Green infrastructure. The policy states, “London’s network of green and open spaces, and green features in the built environment, should be protected and enhanced,” and that “green infrastructure should be planned, designed and managed in an integrated way to achieve multiple benefits.” (Authority 2021). This policy closely aligns with policies G5 Urban greening, SI4 Manage heat risk, and GG3 Creating a health city. The proper protection and implementation of green infrastructure is critical to mitigating the urban heat island effect and, by extension, reducing heat-related illness in the city.\nLondon is widely considered one of the greenest cities in the world. This fact, however, should not be taken for granted, nor should it be used to gloss over ever-present disparities in access to greenspace and green infrastructure. The “London’s Green Cover” tool available via the London Datastore provides a useful way to visualise the difference in green coverage across London boroughs. While the borough of Bromley sees over 73% green coverage, Tower Hamlets has just over 25% cover (Authority 2024). Clearly, there is ample opportunity to improve green infrastructure in London, with certain boroughs set to benefit disproportionately. Furthermore, since green spaces are an important mitigating factor against urban heat, increasing green infrastructure in the boroughs with the least coverage is an important step in promoting equitable climate resilience and public health outcomes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4  Policy",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nRemote sensing stands to significantly assist in the implementation of policy G1 Green infrastructure and related goals. As we saw in the practical last week, applying the Normalized Difference Vegetation Index (NDVI) to Landsat 9 data was effective in identifying areas of high and low vegetation density. This week, however, I’d like to focus more on remote sensing in the context of the urban heat island effect.\nMeasuring surface temperature variation across a large study area is central to assessing the extent and intensity of the urban heat island effect in a city. Data from the Thermal Infrared Sensor 2 (TIRS-2) on Landsat 9 makes this possible. TIRS-2 is an advanced thermal sensor that collects data in two spectral bands to detect land surface temperature. The design improves upon the original TIRS on Landsat 8 by providing better measurement reliability and minimized interference (CITE). Both spectral bands of TIRS-2 offer a spatial resolution of 100 meters. This spatial resolution remains small enough to identify localized hotspots in a city. Using this data, it would be possible to visualize surface temperature patterns in London and identify areas where urban heat is most intense.\nAs we saw, greenness in London is unevenly spatially distributed. The urban heat effect is more pronounced in areas with less heat mitigating infrastructure, such as high-albedo surfaces or tree cover. An analysis of surface temperatures in the city could highlight areas where the urban heat effect is particularly intense. Paired with an NDVI analysis like we saw last week, an approach could be developed pinpoint hotspots characterized by both high temperatures and low vegetation cover, and in turn inform targeted green development. Such a method would work to tackle policies G1, G5, SI4 and GG3 while targeting interventions where they are needed most.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThis exercise reminded me of the complexity of urban systems and how closely intertwined policy goals are. In some ways, this interconnectedness simplifies decision-making (for example, enhancing green infrastructure inherently mitigates heat risk and improves public health outcomes), however, it also underscores the challenges of urban planning, where policy priorities may sometimes be in tension and interventions can have unintended consequences. This highlights the importance of a holistic, well-informed approach that considers the full range of urban dynamics before implementing changes. A deep understanding of the city, its policies, and the synergies between them is crucial to ensuring that interventions are both effective and equitable.\nWhile researching this topic further, I came across a heat vulnerability report for London developed in partnership with ARUP (Figueiredo et al. 2024). Their analysis relies on UHeat, a proprietary digital tool that integrates climate and remote sensing data, including outputs from the Surface Urban Energy and Water Balance Scheme (SUEWS). Similarly, New York City has developed a Heat Vulnerability Index, which incorporates factors such as green space access. However, details on their methodologies are limited, making it difficult to assess or replicate their approaches in more detail. This lack of transparency raises concerns about reproducibility and accessibility, particularly for cities with fewer resources.\nNonetheless, these examples illustrate the potential of combining remote sensing techniques to develop useful climate resilience tools. The integration of NDVI analysis with thermal mapping, could offer an efficient way to assess urban heat vulnerability. More broadly, it emphasizes how different remote sensing datasets can be layered effectively. This expands the possibilities for evidence-based urban planning and reinforces the role of remote sensing in shaping climate adaptation strategies.\n\n\n\n\nAuthority, Greater London. 2021. “The London Plan 2021.” March 1, 2021. https://www.london.gov.uk/programmes-strategies/planning/london-plan/the-london-plan-2021-table-contents.\n\n\n———. 2024. “Green Cover Map.” September 2024. https://apps.london.gov.uk/green-cover/?layers=tree-canopy,green,blue&pos=9.5/51.48800/-0.08750.\n\n\nFigueiredo, Annette, Holly Smith, Emer O’Connell, Vivienne Lang, Agnese Manfrin, and Anna Mavrogianni. 2024. “Properties Vulnerable to Heat Impacts in London: Prioritisation for Adaptation Interventions.”",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Corrections",
    "section": "",
    "text": "3.1 Summary\nThis week, we took a closer look at data correction, joining, and enhancement. These days, a lot of remote sensing data comes nicely packaged as ARD (Analysis Ready Data). As the name suggests, this means the data has been pre-processed, and the necessary corrections completed. Still, it is important to understand the underlying processes.\nData correction for remote sensing can be broken up into geometric, atmospheric, topographic, and radiometric corrections.\nGeometric correction refers to the process of aligning points in the image to a reference dataset. An interesting consideration is forward vs. backward mapping, where forward mapping projects input pixels to output coordinates, while backward mapping identifies the corresponding source pixel for each output pixel.\nWhen satellites collect data, interference from the atmosphere can distort the imagery. Depending on what features of the image we’re interested in, atmospheric correction may be necessary. Although Jensen suggests that atmospheric correction is only needed in certain circumstances, we were told it’s best practice to apply it consistently. We learned about methods like Dark Object Subtraction (DOS) and Pseudo-Invariant Features (PIFs).\nTopographic correction removes distortion caused by variations in terrain. This is especially important when imaging areas with significant elevation changes, as the angle of the satellite (nadir vs. off-nadir) can create shadows and illumination differences.\nFinally, radiometric correction refers to adjusting the raw data to account for sensor noise and inconsistencies. Raw Earth observation data often comes in the form of Digital Numbers (DN), representing pixel intensity. To make the data meaningful, it needs to be converted to spectral radiance through radiometric calibration.\nWe explored data joining and image enhancement in this week’s practical. I found it interesting to apply the NDVI ratio to NYC. In visualizing this data, it was clear how certain areas of the city have disproportionately more vegetation than others (Figure 1).\nLearning more about Earth observation data correction gave me a new appreciation for Analysis Ready Data. This pre-processing significantly reduces the workload, allowing researchers to focus more on data interpretation and analysis rather than spending extensive time on initial corrections. Still, if I were given ARD, I think it would still be important to consider which correction methods were used and how this might impact the product I’ve received.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Corrections",
    "section": "",
    "text": "Figure 1. Practical Output of NYC NDVI &gt; 20%.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  Corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nAfter learning some of the different methods for correcting remote sensing data, I was curious about research on comparing methods and if there was any work on establishing the contexts in which certain corrections might be more suitable than others.\n\n3.2.1 Geometric correction\nOne paper I found interest is a study by Bannari et al. (1995). In their work, they review mathematical models of geometric corrections for remote sensing images. They outline a number of different error sources that create distortions of images and explore three mathematical models used to conduct geometric correction: equations of collinearity, equations of collinearity related to celestial mechanics and polynomial equations. They find that using an equation of collinearity related to celestial mechanics is the best for mapping that requires high precision. The polynomial method was also found to produce good results under certain conditions.\n\n\n3.2.2 Atmospheric correction\nWork by Hadjimitsis et al. (2004), meanwhile, focuses on the effectiveness of atmospheric correction algorithms. The authors highlight the high number of atmospheric correction algorithms out there while pointing out a gap in research identifying the benefits of different approaches. The authors compare methods by applying them to a series of Landsat-5 images of 10 reservoirs in the Lower Thames valley. They found that the dark object subtraction (DOS) method worked the best most consistently. The method using pseudo-invariant points was less effective, which they attribute to the lack of a solid base image for normalizing the others.\n\n\n3.2.3 Thoughts\nWhile I recognize that these studies are relatively old, it was interesting nonetheless to consider how methods for correcting Earth observation data have developed and the way researchers have debated various approaches. The papers underscore that no single method is always the best, and the importance of considering the specific context and data being analyzed. While pre-processed data may be convenient, this research reminded me the importance of remaining critical of all data that I’m given and ensuring that I understand the corrections that have been applied.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nConsidering the variety of methods available for data correction, I was surprised by the number of different approaches and how these could yield different results. Honestly, I expected correction to be far more straightforward, with less room for error. This week impressed on me the importance of understanding the nuances inherent to different methods for identifying potential biases in data. It’s almost overwhelming to determine the most appropriate technique for a given research question, especially when multiple valid options exist. That being said, flexibility in correction methods can also be useful depending on the data available and specific research question. For example, for atmospheric correction, dark object subtraction (DOS) could be more suitable than psuedo-invariant features (PIFs) in an image without a clear reliable reference point.\nExploring image enhancement approaches in the practical further highlighted the range of tools available for research. I enjoyed seeing these tools in action for a practical application. When applying the NDVI ratio to New York City, I was struck by how relatively simple a method this was to identify areas of greenspace in the city. It made me think about the range policy applications, such as examining access to greenspace in different neighbourhoods or targeting areas for increased urban greening.\nOverall, this week I gained a deeper appreciation for the foundational work done by researchers in this field. In particular, learning about Virginia Norwood’s contributions was eye-opening. Mainly, I was surprised I had never heard of her before. Given that many women in science often go unrecognized and under-celebrated, I’m glad I had the chance to learn more about her life and achievements (Figure 2). I had also somehow always assumed that remote sensing was far newer a field, so it was unexpected to learn how technology that was developed back in the 1970s is still so relevant today. Moving forward, I will be curious to see how this background knowledge will inform the way I interpret remote sensing work and research.\n\n\n\nFigure 2. Go Norwood! Source: NASA\n\n\n\n\n\n\nBannari, A., D. Morin, G. B. Bénié, and F. J. Bonn. 1995. “A Theoretical Review of Different Mathematical Models of Geometric Corrections Applied to Remote Sensing Images.” Remote Sensing Reviews 13 (1–2): 27–47. https://doi.org/10.1080/02757259509532295.\n\n\nHadjimitsis, D. G., C. R. I. Clayton, and V. S. Hope. 2004. “An Assessment of the Effectiveness of Atmospheric Correction Algorithms Through the Remote Sensing of Some Reservoirs.” International Journal of Remote Sensing 25 (18): 3651–74. https://doi.org/10.1080/01431160310001647993.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Intro to Google Earth Engine",
    "section": "",
    "text": "5.1 Summary\nThis week, we had our first go at using Google Earth Engine (GEE). During the lecture, we covered GEE fundamentals, including an introduction to its basic object classes (Figure 1) and key terminology. We explored the advantages of using GEE, particularly its cloud-based processing capabilities, emphasizing the importance of minimizing loops and using server-side functions to optimize performance. It was impressive to hear about how the same task that would take hours to process in R can be executed in mere seconds using GEE. Some other important notes include the fact that GEE operates on a 256x256 grid system, where aggregation plays a crucial role in handling large datasets, and how the software automatically reprojects data.\nWe moved on to getting familiar with the GEE interface and typical processes, from geometry operations to machine learning. For the practical session, we experimented with some of these, including Principal Component Analysis (PCA) and Normalized Difference Vegetation Index (NDVI) calculations. This was my first time coding in Java, which came with its own learning curve. It was interesting to see the differences in working with R and Java particularly during PCA, where a process that would have taken just a single line in R actually was much less efficient in GEE. Figure 3 shows the NDVI output produced for Delhi.\nOverall, it struck me that GEE makes remote sensing analysis a lot easier by reducing the need for local computing resources. On the other hand, its proprietary nature raises concerns. Given that Google owns and maintains the platform, there is always a risk that it could be restricted or discontinued, which is particularly problematic considering the growing reliance on GEE in research. The broader issue of depending on big tech firms for essential scientific tools is especially relevant in today’s political climate, where corporate decisions can have far-reaching consequences for research and data accessibility.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Intro to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Intro to Google Earth Engine",
    "section": "",
    "text": "Figure 1. Google Earth Engine Object Classes. Source: GEE\n\n\n\n\n\n\nFigure 2. NDVI Output for Delhi.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Intro to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#applications",
    "href": "week5.html#applications",
    "title": "5  Intro to Google Earth Engine",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nGoogle Earth Engine has seen a significant surge in adoption among researchers over the past decade, primarily due to its ability to efficiently handle big data and provide access to an extensive collection of satellite imagery and geospatial datasets from a single platform. Many of the articles I reviewed this week emphasize these advantages, particularly in terms of computational efficiency and accessibility.\nOne of GEE’s most notable strengths is its ability to drastically reduce processing time by leveraging cloud-based servers. This is especially beneficial when dealing with the “big data problem” posed by heterogeneous satellite imagery collected from multiple sensors, which would otherwise require substantial local computing power (Zhao et al. 2021). By enabling large-scale analysis that would be prohibitively time-consuming on traditional systems, GEE has become an invaluable tool in remote sensing research. For instance, in assessing the efficiency of GEE in crop mapping, Sheletov et al. (@-shelestovExploringGoogleEarth2017) found that Google Earth Engine was highly effective in enabling access to remote sensing products and provided robust pre-processing capabilities.\nBeyond computational speed, another major advantage of GEE is its accessibility, which democratizes access to high-level geospatial analysis and enables researchers to conduct long-term, large-scale studies that would typically be computationally prohibitive. The ability to analyze long-term environmental trends is particularly powerful in studies of land use and land cover change. Researchers have used GEE to investigate transformations in various ecosystems, from tracking land cover changes near river basins (Zurqani et al. 2018) to monitoring global forest change over decades (Hansen et al. (2013)). Work by Hansen et al. [@-hansenHighResolutionGlobalMaps2013] work particularly stood out to me, showcasing GEE’s capability to process massive datasets at a global scale, which would be nearly impossible with conventional GIS and remote sensing tools.\nGiven the benefits to using GEE, it doesn’t come as much of a surprise that many earth observation researchers prefer this tool today. Its ability to streamline complex analyses while providing easy access to datasets has transformed the way large-scale earth observation studies are conducted.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Intro to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Intro to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nThis week highlighted many of the advantages of GEE, particularly its efficiency in data access and processing. Through this week’s lecture, practical, and reviewed literature, it became clear that GEE is an exciting tool that opens up many avenues for research. However, it is equally important to acknowledge some of the platform’s limitations.\nA key concern, as mentioned in the summary, is that Google has full control over GEE. If the company were to restrict or eliminate free access in the future, researchers who rely heavily on the platform could face significant challenges. As we’ve seen throughout this course, Earth observation research plays a crucial role in informing policy, particularly in environmental and urban planning. To ensure the continuity of their work, researchers should avoid over-reliance on GEE and maintain proficiency in alternative tools as well. Open-source programs like R, for instance, provide greater long-term stability. This raises broader questions about the role of private corporations in shaping access to scientific data and analytical tools. While GEE currently serves as a powerful resource, dependency on Google’s infrastructure underscores the importance of advocating for more open-access platforms.\nAs I begin to work more with GEE, I am increasingly I am increasingly curious about the differences with R, and the respective advantages and disadvantages of each. As we saw in the practical this week, while GEE excels in handling large datasets and reducing processing time, R can sometimes be more efficient for specific analytical tasks. To me, this fact reinforced the importance of being familiar with multiple tools to select the best approach for a given research question. Personally, I currently feel more comfortable with R due to my greater experience with it and would likely default to it unless working with particularly large or computationally intensive datasets. It will be interesting to see how my perspective changes as I continue to explore and work with GEE.\n\n\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nZhao, Qiang, Le Yu, Xuecao Li, Dailiang Peng, Yongguang Zhang, and Peng Gong. 2021. “Progress and Trends in the Application of Google Earth and Google Earth Engine.” Remote Sensing 13 (18, 18): 3778. https://doi.org/10.3390/rs13183778.\n\n\nZurqani, Hamdi A., Christopher J. Post, Elena A. Mikhailova, Mark A. Schlautman, and Julia L. Sharp. 2018. “Geospatial Analysis of Land Use Change in the Savannah River Basin Using Google Earth Engine.” International Journal of Applied Earth Observation and Geoinformation 69 (July): 175–85. https://doi.org/10.1016/j.jag.2017.12.006.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Intro to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Classification I",
    "section": "",
    "text": "6.1 Summary\nAfter going through Google Earth Engine basics last week, we were ready to delve deeper into classification methods using GEE. The lecture provided an overview of methodologies and applications. We started by looking at how classification builds on expert systems (Figure 1), which we learned are systems that use human knowledge to solve problems.\nMachine learning (ML), as a computational modeling of the learning process, mimics inductive learning, whereby humans generalize from examples to reach logical conclusions. For computers to achieve this, ML searches through data to explain patterns and make predictions. I was surprised to learn I’d already worked with ML before with regression analysis. We then spent time focusing on a few specific supervised classification methods, including classification and regression trees (CART), random forests, and support vector machines.\nClassification trees categorize data into discrete classes using classic “yes/no” decision tree models. In contrast, regression trees predict continuous values, making them useful when linear regression is insufficient. These models divide data into segments, placing breaks where the sum of squared residuals (SSR) is minimized. The root variable is chosen to reduce Gini impurity, and methods like setting a minimum observation threshold (e.g., 20 pixels in Earth observation) or weakest-link pruning help prevent overfitting.\nRandom forests extend CART by combining multiple decision trees, where the most common outcome (“votes”) across trees determines the final classification. I applied this method in the practical exercise, using it to classify land cover in Boston (Figure 2)\nLastly, we covered SVMs, which function similarly to logistic regression but incorporate additional parameters for flexibility. Adjusting factors like the kernel type, C (which influences decision boundary maximization), and gamma (which controls the influence of training examples) alters the classification. While these methods provide high accuracy, they also present challenges. SVMs and random forests essentially function as “black box” models, making their decision processes less interpretable than some other classification methods, like decision trees. This issue resonated with me. While decision trees provide step-by-step walkthroughs, the logic behind an SVM or random forest is less clear. This can cause issues with transparency, making it difficult explain to why classifications are presented as such. That said, through the practical I was impressed by how such complex methods can be executed in relatively little code.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification I",
    "section": "",
    "text": "Figure 1. Expert Systems. Source: Aftab Alam\n\n\n\n\n\n\n\n\nFigure 2. Random Forest Classification Output for LULC in Boston, MA, distinguishing high-density urban areas (dark pink), low-density urban areas (pink), forests (dark green), grass (light green) and water (purple).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nFollowing this week’s lecture, I was curious to explore previous work using these classification methods. I decided to focus particularly on random forests and support vector machines.\nIn a study by Svoboda et al. [@-svobodaRandomForestClassification2022], the authors utilize random forests in Google Earth Engine to classify land in Czechia for the LULUCF (Land Use, Land-Use Change, and Forestry) greenhouse gas inventory. While Czechia traditionally uses cadastral data for this task in the past, the study highlighted the potential for Earth observation data to be applied in this context. I noticed the authors use the median method for mosaicking, aligning with good practices we discussed in class. Overall, the model achieved the highest accuracy for cropland and woodland but was slightly less effective for settlements (Svoboda et al. 2022). The authors highlight the potential of cloud-based classification with EO data to enhance LULUCF applications globally and emphasize the need for stronger collaboration between end-users and EO experts to maximize its impact (Svoboda et al. 2022).\nSupport vector machines have also been adopted for remote sensing tasks. Yan and Huang [@-yanDetectingSeaIce2019], for example, apply SVMs to detect sea ice, arguing that they provide better accuracy than maximum likelihood classification. A key advantage highlighted was the model’s robustness with limited training data. The study was particularly interesting because it addressed a gap in the application of SVMs to sea ice detection. Furthermore, the authors utilize Delay Doppler Mapping data from satellite TDS-1, a form of remote sensing data I hadn’t encountered before. They concluded that SVMs outperformed neural network (NN) and convolutional neural network (CNN) algorithms (Yan and Huang 2019). While their analysis was not conducted in GEE, it still provided valuable insights into applying classification methods and working with new datasets.\nThese readings increased my appreciation for striking a balance between model complexity and interpretability. The more I explore EO applications, the more critically I can assess them. I found Svoboda et al. (Svoboda et al. 2022) particularly effective in clearly outlining their policy objectives, tools, and methods, making the study easy to follow. In contrast, the second paper was less straightforward in connecting its findings to broader applications. I believe the most valuable research not only presents methodological advancements but also links them to actionable outcomes, ensuring their relevance beyond academic contexts.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nDuring the lecture this week, we skipped over the maximum likelihood portion of the presentation. It was mentioned that, these days, machine learning is more relevant. This made me wonder, are there still contexts where maximum likelihood remains useful? While ML approaches dominate, it’s important to remember that no model is universally superior.\nWhile I read the papers above, I was reminded that even sophisticated ML models are not infallible. For instance, the Czechia study showed lower accuracy for urban areas, demonstrating that advanced methods still struggle with certain classifications. As ML continues to shape classification tasks, researchers and practitioners must remain aware of its limitations, ensuring results are taken with caution rather than assumed to be inherently superior. This also links back to interpretability. While methods like random forests and SVMs may offer higher accuracy, their complexity can make them difficult to interpret. This trade-off between performance and transparency is crucial, particularly in contexts where decisions in analysis must be explainable to stakeholders.\nWith artificial intelligence now a major topic of discussion across many fields, this week’s content also led me to wonder how advanced AI and remote sensing might evolve together, and how the classification methods we are learning today will adapt. In a similar way that machine learning methods pose interpretability issues, AI-based approaches often function “black boxes” with decision-making processes that are difficult to trace. As AI inevitably weaves its way the way researchers conduct geospatial analysis, it will be critical to carry forward the lessons learned from ML challenges, particularly regarding model transparency and bias in training data.\nOne of the key takeaways for me from this week’s content is that high accuracy alone is not enough. Methods should be interpretable, reproducible, and applicable to real-world scenarios.\n\n\n\n\nSvoboda, Jan, Přemysl Štych, Josef Laštovička, Daniel Paluba, and Natalia Kobliuk. 2022. “Random Forest Classification of Land Use, Land-Use Change and Forestry (LULUCF) Using Sentinel-2 Data—A Case Study of Czechia.” Remote Sensing 14 (5, 5): 1189. https://doi.org/10.3390/rs14051189.\n\n\nYan, Qingyun, and Weimin Huang. 2019. “Detecting Sea Ice From TechDemoSat-1 Data Using Support Vector Machines With Feature Selection.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 12 (5): 1409–16. https://doi.org/10.1109/JSTARS.2019.2907008.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  }
]