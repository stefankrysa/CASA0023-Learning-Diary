[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Welcome\n\n\n\nSource: European Space Agency.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Remote Sensing Basics",
    "section": "",
    "text": "1.1 Summary\nThis week, we got started learning about the basics of remote sensing and earth observation. This started with an overview of how sensors collect data. Satellites can detect electromagnetic waves passively or actively, whereby data is either reflected off an object by the sun’s light or a sensor produces its own energy source for illumination, respectively. We learned the fundamentals of EMR, such as identifying wavelength or amplitude, and the range of the electromagnetic spectrum, as depicted in Figure 1. When EMR interacts with a surface, what is reflected is often modified due to energy being absorbed, transmitted through, or scattered. This allows for the detection of spectral signatures, which are unique patterns of reflected or emitted electromagnetic radiation that specific materials exhibit. We also touched on important concepts of spatial, spectral, temporal, and radiometric resolution, which define the characteristics and quality of remotely sensed data.\nIn the practical, we took a closer look at working with Sentinel-2 and Landsat data in SNAP. We started by loading and merging different bands to play around with how they combined to create composite images. True-colour composites create an image that replicate natural colours familiar to humans, while false-colour composites utilize combinations of non-visible bands, such as near-infrared, along with visible bands, to highlight specific features or phenomena, like vegetation. We moved on to compute the tasselled cap transformation in order identify areas of brightness, greenness and wetness, a method particularly useful for identifying urban land use. Then, to classify different land use areas, we selected and exported pixels covering a variety of land covers. Upon loading this data into R, plotting the difference in pixel values across bands highlighted the unique spectral signatures of various land types.\nGiven that Sentinel data typically has a lower spatial and temporal resolution compared to Landsat, I am curious about why researchers would continue to opt for using Landsat data. Since Landsat has been in operation for longer than Sentinel, Landsat provides a longer time range of data, which could be useful for certain research questions. Still, I wonder about any other upsides to using data from one satellite over the other.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote Sensing Basics</span>"
    ]
  },
  {
    "objectID": "intro.html#summary",
    "href": "intro.html#summary",
    "title": "1  Remote Sensing Basics",
    "section": "",
    "text": "Figure 1. Electromagnetic Spectrum. Source: https://upload.wikimedia.org/wikipedia/commons/c/cf/EM_Spectrum_Properties_edit.svg",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote Sensing Basics</span>"
    ]
  },
  {
    "objectID": "intro.html#applications",
    "href": "intro.html#applications",
    "title": "1  Remote Sensing Basics",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nSince getting familiar with Landsat and Sentinel imagery formed a major component of the practical, I was curious to find existing research using these sources. I found Landsat and Sentinel imagery serve as valuable resources for monitoring environmental and land use.\n\n1.2.1 Sentinel research\nResearch by Farhadi et al. (2025) was one paper that stood out to me. In this work, the authors use Sentinel imagery at a 10m resolution to build a new spectral index for flood mapping. Specifically, the method utilizes visible and NIR bands to discriminate water characteristics. This new technique, they posit, provides a more efficient method for monitoring flood zones without reliance on thresholding methods, whereby different selections can significantly change results. An index accuracy of above 97% for pre-flood, flooded, and post-flood extraction on two test areas are promising results for their proposed method. Successfully developing this method would not have been possible if not for the high spatial resolution of Sentinel imagery.\n\n\n1.2.2 Landsat research\nWork by Hillson et al. (2019), meanwhile, relies on Landsat imagery. In their research, they aim to estimate population density using a regression model with covariates derived from Landsat imagery of Bo, Sierre Leone. Analysis began with 379 Landsat 5 thematic mapper candidate covariates before narrowing down the selection to six for the final model. Covariates encompass a range of data from Landsat, which include pixel values and a variety of transformations of these values. The final model was found to be effective for predicting population density. This was true at even at a 30m spatial resolution. The authors highlight the utility of such a method to estimate local populations in environments where census data is old or unreliable.\n\n\n1.2.3 Thoughts\nWhile both works provided an interesting showcase of the practical applications of earth observation in different settings, as someone new to this field it was interesting for me to see how the researchers communicated their findings differently. I found the analysis done by Farhadi et al. (2025) to be far simpler to follow than that of Hillson et al. (2019). To me, the former did a better job of outlining their methods in an easy-to-understand way. Perhaps more complex papers will make more sense later in this course, but I also think this points to an important issue in remote sensing research: how to make the work accessible and easy to understand for the general public. As this field gains traction and recognition among policy-makers, it is increasingly important to communicate research in a way that is accessible to all, not just academics.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote Sensing Basics</span>"
    ]
  },
  {
    "objectID": "intro.html#reflection",
    "href": "intro.html#reflection",
    "title": "1  Remote Sensing Basics",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nIn the context of climate change and rapid urbanization across the globe, earth observation presents fascinating opportunities to better understand and respond to environmental and land use change.\nSentinel imagery, given at a high spatial and temporal resolution, allows researchers to frequently monitor less-accessible areas with great accuracy. This capability can be leveraged both proactively, by assessing risks and guiding the development of preventative infrastructure, and reactively, by coordinating emergency responses following extreme weather events. Such applications are critical for effectively targeting aid and implementing mitigation strategies to enhance resilience against future events. As we have seen, highly effective methods for monitoring flood zones have already been developed.\nWe also saw the uses of earth observation for urban environments. Monitoring land use and change is valuable to understanding settlement and urban growth patterns and can be employed to make better-informed planning decisions for sustainable growth. Landsat, in operation for over 40 years now, provides a huge range of data for a long period of time. This could be particularly useful in studies analyzing land use change over time.\nIt was interesting to think about how the tools we employed in the practical this week are applicable in a broader context to monitoring landscapes inside and out of cities. Through techniques such as land classification it is possible to conduct analyses of land use and cover applicable to the issues outlined above. This practical was also a humbling reminder of the value of user-friendly software. By running into a handful of issues using SNAP, I was reminded not to take for granted the flexibility inherent to tools like R.\n\n\n\n\nFarhadi, Hadi, Hamid Ebadi, Abbas Kiani, and Ali Asgary. 2025. “Introducing a New Index for Flood Mapping Using Sentinel-2 Imagery (SFMI).” Computers & Geosciences 194 (January): 105742. https://doi.org/10.1016/j.cageo.2024.105742.\n\n\nHillson, Roger, Austin Coates, Joel D. Alejandre, Kathryn H. Jacobsen, Rashid Ansumana, Alfred S. Bockarie, Umaru Bangura, Joseph M. Lamin, and David A. Stenger. 2019. “Estimating the Size of Urban Populations Using Landsat Images: A Case Study of Bo, Sierra Leone, West Africa.” International Journal of Health Geographics 18 (1): 16. https://doi.org/10.1186/s12942-019-0180-1.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote Sensing Basics</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Presentation",
    "section": "",
    "text": "xqx results='asis', echo=FALSE} xaringanExtra::embed_xaringan(url = \"https://stefankrysa.github.io/CASA0023-Xaringan-Presentation/\", ratio = \"16:9\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Presentation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Adeli, Sarina, Bahram Salehi, Masoud Mahdianpari, Lindi J. Quackenbush,\nBrian Brisco, Haifa Tamiminia, and Stephen Shaw. 2020. “Wetland\nMonitoring Using SAR Data: A Meta-Analysis and\nComprehensive Review.” Remote Sensing 12\n(14, 14): 2190. https://doi.org/10.3390/rs12142190.\n\n\nBannari, A., D. Morin, G. B. Bénié, and F. J. Bonn. 1995. “A\nTheoretical Review of Different Mathematical Models of Geometric\nCorrections Applied to Remote Sensing Images.” Remote Sensing\nReviews 13 (1–2): 27–47. https://doi.org/10.1080/02757259509532295.\n\n\nCechim Junior, Clovis, Araki Hideo, and Rodrigo and de Campos Macedo.\n2023. “Object-Based Image Analysis\n(OBIA) and Machine Learning (ML)\nApplied to Tropical Forest Mapping Using\nSentinel-2.” Canadian Journal of Remote Sensing\n49 (1): 2259504. https://doi.org/10.1080/07038992.2023.2259504.\n\n\nFarhadi, Hadi, Hamid Ebadi, Abbas Kiani, and Ali Asgary. 2025.\n“Introducing a New Index for Flood Mapping Using Sentinel-2\nImagery (SFMI).” Computers & Geosciences 194\n(January): 105742. https://doi.org/10.1016/j.cageo.2024.105742.\n\n\nFigueiredo, Annette, Holly Smith, Emer O’Connell, Vivienne Lang, Agnese\nManfrin, and Anna Mavrogianni. 2024. “Properties\nVulnerable to Heat Impacts in\nLondon: Prioritisation for Adaptation\nInterventions.”\n\n\nGLA. 2021. “The London Plan 2021.” March 1,\n2021. https://www.london.gov.uk/programmes-strategies/planning/london-plan/the-london-plan-2021-table-contents.\n\n\n———. 2024. “Green Cover Map.” September 2024.\nhttps://apps.london.gov.uk/green-cover/?layers=tree-canopy,green,blue&pos=9.5/51.48800/-0.08750.\n\n\nHadjimitsis, D. G., C. R. I. Clayton, and V. S. Hope. 2004. “An\nAssessment of the Effectiveness of Atmospheric Correction Algorithms\nThrough the Remote Sensing of Some Reservoirs.” International\nJournal of Remote Sensing 25 (18): 3651–74. https://doi.org/10.1080/01431160310001647993.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A.\nTyukavina, D. Thau, et al. 2013. “High-Resolution Global\nMaps of 21st-Century Forest Cover Change.”\nScience 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nHillson, Roger, Austin Coates, Joel D. Alejandre, Kathryn H. Jacobsen,\nRashid Ansumana, Alfred S. Bockarie, Umaru Bangura, Joseph M. Lamin, and\nDavid A. Stenger. 2019. “Estimating the Size of Urban Populations\nUsing Landsat Images: A Case Study of Bo, Sierra Leone, West\nAfrica.” International Journal of Health Geographics 18\n(1): 16. https://doi.org/10.1186/s12942-019-0180-1.\n\n\nHu, Deyong, Shanshan Chen, Kun Qiao, and Shisong Cao. 2017.\n“Integrating CART Algorithm and Multi-Source Remote\nSensing Data to Estimate Sub-Pixel Impervious Surface Coverage: A Case\nStudy from Beijing Municipality,\nChina.” Chinese Geographical Science 27\n(4): 614–25. https://doi.org/10.1007/s11769-017-0882-x.\n\n\nTsokas, Arsenios, Maciej Rysz, Panos M. Pardalos, and Kathleen Dipple.\n2022. “SAR Data Applications in Earth Observation:\nAn Overview.” Expert Systems with\nApplications 205 (November): 117342. https://doi.org/10.1016/j.eswa.2022.117342.\n\n\nZhang, Tianwen, Xiaoling Zhang, Jianwei Li, Xiaowo Xu, Baoyou Wang, Xu\nZhan, Yanqin Xu, et al. 2021. “SAR Ship Detection\nDataset (SSDD): Official Release and\nComprehensive Data Analysis.” Remote\nSensing 13 (18, 18): 3690. https://doi.org/10.3390/rs13183690.\n\n\nZhao, Qiang, Le Yu, Xuecao Li, Dailiang Peng, Yongguang Zhang, and Peng\nGong. 2021. “Progress and Trends in the\nApplication of Google Earth and Google\nEarth Engine.” Remote Sensing 13 (18, 18): 3778.\nhttps://doi.org/10.3390/rs13183778.\n\n\nZurqani, Hamdi A., Christopher J. Post, Elena A. Mikhailova, Mark A.\nSchlautman, and Julia L. Sharp. 2018. “Geospatial Analysis of Land\nUse Change in the Savannah River Basin Using Google\nEarth Engine.” International Journal of Applied Earth\nObservation and Geoinformation 69 (July): 175–85. https://doi.org/10.1016/j.jag.2017.12.006.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Policy",
    "section": "",
    "text": "4.1 Summary\nThe London Plan 2021 (GLA 2021) was developed by the Greater London Authority and acts as a framework to guide the spatial development of the Greater London Area over the next 25 or so years. All development decisions following the adaptation of the Plan in 2021 should, in theory, adhere to the policies outlined in the document. The Plan covers a range of topics and issues, organized into categories of Good Growth, Spatial Development Patterns, Design, Housing, Social Infrastructure, Economy, Heritage and Culture, Green Infrastructure and Natural Environment, Sustainable Infrastructure and, finally, Transport.\nMy policy of focus is G1 Green infrastructure. The policy states, “London’s network of green and open spaces, and green features in the built environment, should be protected and enhanced,” and that “green infrastructure should be planned, designed and managed in an integrated way to achieve multiple benefits.” (GLA 2021). This policy closely aligns with policies G5 Urban greening, SI4 Manage heat risk, and GG3 Creating a health city. The proper protection and implementation of green infrastructure is critical to mitigating the urban heat island effect and, by extension, reducing heat-related illness in the city.\nLondon is widely considered one of the greenest cities in the world. This fact, however, should not be taken for granted, nor should it be used to gloss over ever-present disparities in access to greenspace and green infrastructure. The “London’s Green Cover” tool available via the London Datastore provides a useful way to visualise the difference in green coverage across London boroughs. While the borough of Bromley sees over 73% green coverage, Tower Hamlets has just over 25% cover (GLA 2024). Clearly, there is ample opportunity to improve green infrastructure in London, with certain boroughs set to benefit disproportionately. Furthermore, since green spaces are an important mitigating factor against urban heat, increasing green infrastructure in the boroughs with the least coverage is an important step in promoting equitable climate resilience and public health outcomes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4  Policy",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nRemote sensing stands to significantly assist in the implementation of policy G1 Green infrastructure and related goals. As we saw in the practical last week, applying the Normalized Difference Vegetation Index (NDVI) to Landsat 9 data was effective in identifying areas of high and low vegetation density. This week, however, I’d like to focus more on remote sensing in the context of the urban heat island effect.\nMeasuring surface temperature variation across a large study area is central to assessing the extent and intensity of the urban heat island effect in a city. Data from the Thermal Infrared Sensor 2 (TIRS-2) on Landsat 9 makes this possible. TIRS-2 is an advanced thermal sensor that collects data in two spectral bands to detect land surface temperature. The design improves upon the original TIRS on Landsat 8 by providing better measurement reliability and minimized interference. Both spectral bands of TIRS-2 offer a spatial resolution of 100 meters. This spatial resolution remains small enough to identify localized hotspots in a city. Using this data, it would be possible to visualize surface temperature patterns in London and identify areas where urban heat is most intense.\nAs we saw, greenness in London is unevenly spatially distributed. The urban heat effect is more pronounced in areas with less heat mitigating infrastructure, such as high-albedo surfaces or tree cover. An analysis of surface temperatures in the city could highlight areas where the urban heat effect is particularly intense. Paired with an NDVI analysis like we saw last week, an approach could be developed pinpoint hotspots characterized by both high temperatures and low vegetation cover, and in turn inform targeted green development. Such a method would work to tackle policies G1, G5, SI4 and GG3 while targeting interventions where they are needed most.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThis exercise reminded me of the complexity of urban systems and how closely intertwined policy goals are. In some ways, this interconnectedness simplifies decision-making (for example, enhancing green infrastructure inherently mitigates heat risk and improves public health outcomes), however, it also underscores the challenges of urban planning, where policy priorities may sometimes be in tension and interventions can have unintended consequences. This highlights the importance of a holistic, well-informed approach that considers the full range of urban dynamics before implementing changes. A deep understanding of the city, its policies, and the synergies between them is crucial to ensuring that interventions are both effective and equitable.\nWhile researching this topic further, I came across a heat vulnerability report for London developed in partnership with ARUP (Figueiredo et al. 2024). Their analysis relies on UHeat, a proprietary digital tool that integrates climate and remote sensing data, including outputs from the Surface Urban Energy and Water Balance Scheme (SUEWS). Similarly, New York City has developed a Heat Vulnerability Index, which incorporates factors such as green space access. However, details on their methodologies are limited, making it difficult to assess or replicate their approaches in more detail. This lack of transparency raises concerns about reproducibility and accessibility, particularly for cities with fewer resources.\nNonetheless, these examples illustrate the potential of combining remote sensing techniques to develop useful climate resilience tools. The integration of NDVI analysis with thermal mapping, could offer an efficient way to assess urban heat vulnerability. More broadly, it emphasizes how different remote sensing datasets can be layered effectively. This expands the possibilities for evidence-based urban planning and reinforces the role of remote sensing in shaping climate adaptation strategies.\n\n\n\n\nFigueiredo, Annette, Holly Smith, Emer O’Connell, Vivienne Lang, Agnese Manfrin, and Anna Mavrogianni. 2024. “Properties Vulnerable to Heat Impacts in London: Prioritisation for Adaptation Interventions.”\n\n\nGLA. 2021. “The London Plan 2021.” March 1, 2021. https://www.london.gov.uk/programmes-strategies/planning/london-plan/the-london-plan-2021-table-contents.\n\n\n———. 2024. “Green Cover Map.” September 2024. https://apps.london.gov.uk/green-cover/?layers=tree-canopy,green,blue&pos=9.5/51.48800/-0.08750.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Corrections",
    "section": "",
    "text": "3.1 Summary\nThis week, we took a closer look at data correction, joining, and enhancement. These days, a lot of remote sensing data comes nicely packaged as ARD (Analysis Ready Data). As the name suggests, this means the data has been pre-processed, and the necessary corrections completed. Still, it is important to understand the underlying processes.\nData correction for remote sensing can be broken up into geometric, atmospheric, topographic, and radiometric corrections.\nGeometric correction refers to the process of aligning points in the image to a reference dataset. An interesting consideration is forward vs. backward mapping, where forward mapping projects input pixels to output coordinates, while backward mapping identifies the corresponding source pixel for each output pixel.\nWhen satellites collect data, interference from the atmosphere can distort the imagery. Depending on what features of the image we’re interested in, atmospheric correction may be necessary. Although Jensen suggests that atmospheric correction is only needed in certain circumstances, we were told it’s best practice to apply it consistently. We learned about methods like Dark Object Subtraction (DOS) and Pseudo-Invariant Features (PIFs).\nTopographic correction removes distortion caused by variations in terrain. This is especially important when imaging areas with significant elevation changes, as the angle of the satellite (nadir vs. off-nadir) can create shadows and illumination differences.\nFinally, radiometric correction refers to adjusting the raw data to account for sensor noise and inconsistencies. Raw Earth observation data often comes in the form of Digital Numbers (DN), representing pixel intensity. To make the data meaningful, it needs to be converted to spectral radiance through radiometric calibration.\nWe explored data joining and image enhancement in this week’s practical. I found it interesting to apply the NDVI ratio to NYC. In visualizing this data, it was clear how certain areas of the city have disproportionately more vegetation than others (Figure 1).\nLearning more about Earth observation data correction gave me a new appreciation for Analysis Ready Data. This pre-processing significantly reduces the workload, allowing researchers to focus more on data interpretation and analysis rather than spending extensive time on initial corrections. Still, if I were given ARD, I think it would still be important to consider which correction methods were used and how this might impact the product I’ve received.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Corrections",
    "section": "",
    "text": "Figure 1. Practical Output of NYC NDVI &gt; 20%.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  Corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nAfter learning some of the different methods for correcting remote sensing data, I was curious about research on comparing methods and if there was any work on establishing the contexts in which certain corrections might be more suitable than others.\n\n3.2.1 Geometric correction\nOne paper I found interest is a study by Bannari et al. (1995). In their work, they review mathematical models of geometric corrections for remote sensing images. They outline a number of different error sources that create distortions of images and explore three mathematical models used to conduct geometric correction: equations of collinearity, equations of collinearity related to celestial mechanics and polynomial equations. They find that using an equation of collinearity related to celestial mechanics is the best for mapping that requires high precision. The polynomial method was also found to produce good results under certain conditions.\n\n\n3.2.2 Atmospheric correction\nWork by Hadjimitsis et al. (2004), meanwhile, focuses on the effectiveness of atmospheric correction algorithms. The authors highlight the high number of atmospheric correction algorithms out there while pointing out a gap in research identifying the benefits of different approaches. The authors compare methods by applying them to a series of Landsat-5 images of 10 reservoirs in the Lower Thames valley. They found that the dark object subtraction (DOS) method worked the best most consistently. The method using pseudo-invariant points was less effective, which they attribute to the lack of a solid base image for normalizing the others.\n\n\n3.2.3 Thoughts\nWhile I recognize that these studies are relatively old, it was interesting nonetheless to consider how methods for correcting Earth observation data have developed and the way researchers have debated various approaches. The papers underscore that no single method is always the best, and the importance of considering the specific context and data being analyzed. While pre-processed data may be convenient, this research reminded me the importance of remaining critical of all data that I’m given and ensuring that I understand the corrections that have been applied.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nConsidering the variety of methods available for data correction, I was surprised by the number of different approaches and how these could yield different results. Honestly, I expected correction to be far more straightforward, with less room for error. This week impressed on me the importance of understanding the nuances inherent to different methods for identifying potential biases in data. It’s almost overwhelming to determine the most appropriate technique for a given research question, especially when multiple valid options exist. That being said, flexibility in correction methods can also be useful depending on the data available and specific research question. For example, for atmospheric correction, dark object subtraction (DOS) could be more suitable than psuedo-invariant features (PIFs) in an image without a clear reliable reference point.\nExploring image enhancement approaches in the practical further highlighted the range of tools available for research. I enjoyed seeing these tools in action for a practical application. When applying the NDVI ratio to New York City, I was struck by how relatively simple a method this was to identify areas of greenspace in the city. It made me think about the range policy applications, such as examining access to greenspace in different neighbourhoods or targeting areas for increased urban greening.\nOverall, this week I gained a deeper appreciation for the foundational work done by researchers in this field. In particular, learning about Virginia Norwood’s contributions was eye-opening. Mainly, I was surprised I had never heard of her before. Given that many women in science often go unrecognized and under-celebrated, I’m glad I had the chance to learn more about her life and achievements (Figure 2). I had also somehow always assumed that remote sensing was far newer a field, so it was unexpected to learn how technology that was developed back in the 1970s is still so relevant today. Moving forward, I will be curious to see how this background knowledge will inform the way I interpret remote sensing work and research.\n\n\n\nFigure 2. Go Norwood! Source: NASA\n\n\n\n\n\n\nBannari, A., D. Morin, G. B. Bénié, and F. J. Bonn. 1995. “A Theoretical Review of Different Mathematical Models of Geometric Corrections Applied to Remote Sensing Images.” Remote Sensing Reviews 13 (1–2): 27–47. https://doi.org/10.1080/02757259509532295.\n\n\nHadjimitsis, D. G., C. R. I. Clayton, and V. S. Hope. 2004. “An Assessment of the Effectiveness of Atmospheric Correction Algorithms Through the Remote Sensing of Some Reservoirs.” International Journal of Remote Sensing 25 (18): 3651–74. https://doi.org/10.1080/01431160310001647993.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Intro to Google Earth Engine",
    "section": "",
    "text": "5.1 Summary\nThis week, we had our first go at using Google Earth Engine (GEE). During the lecture, we covered GEE fundamentals, including an introduction to its basic object classes (Figure 1) and key terminology. We explored the advantages of using GEE, particularly its cloud-based processing capabilities, emphasizing the importance of minimizing loops and using server-side functions to optimize performance. It was impressive to hear about how the same task that would take hours to process in R can be executed in mere seconds using GEE. Some other important notes include the fact that GEE operates on a 256x256 grid system, where aggregation plays a crucial role in handling large datasets, and how the software automatically reprojects data.\nWe moved on to getting familiar with the GEE interface and typical processes, from geometry operations to machine learning. For the practical session, we experimented with some of these, including Principal Component Analysis (PCA) and Normalized Difference Vegetation Index (NDVI) calculations. This was my first time coding in Java, which came with its own learning curve. It was interesting to see the differences in working with R and Java particularly during PCA, where a process that would have taken just a single line in R actually was much less efficient in GEE. Figure 3 shows the NDVI output produced for Delhi.\nOverall, it struck me that GEE makes remote sensing analysis a lot easier by reducing the need for local computing resources. On the other hand, its proprietary nature raises concerns. Given that Google owns and maintains the platform, there is always a risk that it could be restricted or discontinued, which is particularly problematic considering the growing reliance on GEE in research. The broader issue of depending on big tech firms for essential scientific tools is especially relevant in today’s political climate, where corporate decisions can have far-reaching consequences for research and data accessibility.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Intro to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Intro to Google Earth Engine",
    "section": "",
    "text": "Figure 1. Google Earth Engine Object Classes. Source: GEE\n\n\n\n\n\n\nFigure 2. NDVI Output for Delhi.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Intro to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#applications",
    "href": "week5.html#applications",
    "title": "5  Intro to Google Earth Engine",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nGoogle Earth Engine has seen a significant surge in adoption among researchers over the past decade, primarily due to its ability to efficiently handle big data and provide access to an extensive collection of satellite imagery and geospatial datasets from a single platform. Many of the articles I reviewed this week emphasize these advantages, particularly in terms of computational efficiency and accessibility.\nOne of GEE’s most notable strengths is its ability to drastically reduce processing time by leveraging cloud-based servers. This is especially beneficial when dealing with the “big data problem” posed by heterogeneous satellite imagery collected from multiple sensors, which would otherwise require substantial local computing power (Zhao et al. 2021). By enabling large-scale analysis that would be prohibitively time-consuming on traditional systems, GEE has become an invaluable tool in remote sensing research. For instance, in assessing the efficiency of GEE in crop mapping, Sheletov et al. [-Shelestov et al. (2017)] found that Google Earth Engine was highly effective in enabling access to remote sensing products and provided robust pre-processing capabilities.\nBeyond computational speed, another major advantage of GEE is its accessibility, which democratizes access to high-level geospatial analysis and enables researchers to conduct long-term, large-scale studies that would typically be computationally prohibitive. The ability to analyze long-term environmental trends is particularly powerful in studies of land use and land cover change. Researchers have used GEE to investigate transformations in various ecosystems, from tracking land cover changes near river basins (Zurqani et al. 2018) to monitoring global forest change over decades (Hansen et al. 2013). Work by Hansen et al. [-Hansen et al. (2013)] work particularly stood out to me, showcasing GEE’s capability to process massive datasets at a global scale, which would be nearly impossible with conventional GIS and remote sensing tools.\nGiven the benefits to using GEE, it doesn’t come as much of a surprise that many earth observation researchers prefer this tool today. Its ability to streamline complex analyses while providing easy access to datasets has transformed the way large-scale earth observation studies are conducted.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Intro to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Intro to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nThis week highlighted many of the advantages of GEE, particularly its efficiency in data access and processing. Through this week’s lecture, practical, and reviewed literature, it became clear that GEE is an exciting tool that opens up many avenues for research. However, it is equally important to acknowledge some of the platform’s limitations.\nA key concern, as mentioned in the summary, is that Google has full control over GEE. If the company were to restrict or eliminate free access in the future, researchers who rely heavily on the platform could face significant challenges. As we’ve seen throughout this course, Earth observation research plays a crucial role in informing policy, particularly in environmental and urban planning. To ensure the continuity of their work, researchers should avoid over-reliance on GEE and maintain proficiency in alternative tools as well. Open-source programs like R, for instance, provide greater long-term stability. This raises broader questions about the role of private corporations in shaping access to scientific data and analytical tools. While GEE currently serves as a powerful resource, dependency on Google’s infrastructure underscores the importance of advocating for more open-access platforms.\nAs I begin to work more with GEE, I am increasingly I am increasingly curious about the differences with R, and the respective advantages and disadvantages of each. As we saw in the practical this week, while GEE excels in handling large datasets and reducing processing time, R can sometimes be more efficient for specific analytical tasks. To me, this fact reinforced the importance of being familiar with multiple tools to select the best approach for a given research question. Personally, I currently feel more comfortable with R due to my greater experience with it and would likely default to it unless working with particularly large or computationally intensive datasets. It will be interesting to see how my perspective changes as I continue to explore and work with GEE.\n\n\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nShelestov, Andrii, Mykola Lavreniuk, Nataliia Kussul, Alexei Novikov, and Sergii Skakun. 2017. “Exploring Google Earth Engine Platform for Big Data Processing: Classification of Multi-Temporal Satellite Imagery for Crop Mapping.” Frontiers in Earth Science 5 (February). https://doi.org/10.3389/feart.2017.00017.\n\n\nZhao, Qiang, Le Yu, Xuecao Li, Dailiang Peng, Yongguang Zhang, and Peng Gong. 2021. “Progress and Trends in the Application of Google Earth and Google Earth Engine.” Remote Sensing 13 (18, 18): 3778. https://doi.org/10.3390/rs13183778.\n\n\nZurqani, Hamdi A., Christopher J. Post, Elena A. Mikhailova, Mark A. Schlautman, and Julia L. Sharp. 2018. “Geospatial Analysis of Land Use Change in the Savannah River Basin Using Google Earth Engine.” International Journal of Applied Earth Observation and Geoinformation 69 (July): 175–85. https://doi.org/10.1016/j.jag.2017.12.006.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Intro to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Classification I",
    "section": "",
    "text": "6.1 Summary\nAfter going through Google Earth Engine basics last week, we were ready to delve deeper into classification methods using GEE. The lecture provided an overview of methodologies and applications. We started by looking at how classification builds on expert systems (Figure 1), which we learned are systems that use human knowledge to solve problems.\nMachine learning (ML), as a computational modeling of the learning process, mimics inductive learning, whereby humans generalize from examples to reach logical conclusions. For computers to achieve this, ML searches through data to explain patterns and make predictions. I was surprised to learn I’d already worked with ML before with regression analysis. We then spent time focusing on a few specific supervised classification methods, including classification and regression trees (CART), random forests, and support vector machines.\nClassification trees categorize data into discrete classes using classic “yes/no” decision tree models. In contrast, regression trees predict continuous values, making them useful when linear regression is insufficient. These models divide data into segments, placing breaks where the sum of squared residuals (SSR) is minimized. The root variable is chosen to reduce Gini impurity, and methods like setting a minimum observation threshold (e.g., 20 pixels in Earth observation) or weakest-link pruning help prevent overfitting.\nRandom forests extend CART by combining multiple decision trees, where the most common outcome (“votes”) across trees determines the final classification. I applied this method in the practical exercise, using it to classify land cover in Boston (Figure 2)\nLastly, we covered SVMs, which function similarly to logistic regression but incorporate additional parameters for flexibility. Adjusting factors like the kernel type, C (which influences decision boundary maximization), and gamma (which controls the influence of training examples) alters the classification. While these methods provide high accuracy, they also present challenges. SVMs and random forests essentially function as “black box” models, making their decision processes less interpretable than some other classification methods, like decision trees. This issue resonated with me. While decision trees provide step-by-step walkthroughs, the logic behind an SVM or random forest is less clear. This can cause issues with transparency, making it difficult explain to why classifications are presented as such. That said, through the practical I was impressed by how such complex methods can be executed in relatively little code.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification I",
    "section": "",
    "text": "Figure 1. Expert Systems. Source: Aftab Alam\n\n\n\n\n\n\n\n\nFigure 2. Random Forest Classification Output for LULC in Boston, MA, distinguishing high-density urban areas (dark pink), low-density urban areas (pink), forests (dark green), grass (light green) and water (purple).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nFollowing this week’s lecture, I was curious to explore previous work using these classification methods. I decided to focus particularly on random forests and support vector machines.\nIn a study by Svoboda et al. [@-svobodaRandomForestClassification2022], the authors utilize random forests in Google Earth Engine to classify land in Czechia for the LULUCF (Land Use, Land-Use Change, and Forestry) greenhouse gas inventory. While Czechia traditionally uses cadastral data for this task in the past, the study highlighted the potential for Earth observation data to be applied in this context. I noticed the authors use the median method for mosaicking, aligning with good practices we discussed in class. Overall, the model achieved the highest accuracy for cropland and woodland but was slightly less effective for settlements. The authors highlight the potential of cloud-based classification with EO data to enhance LULUCF applications globally and emphasize the need for stronger collaboration between end-users and EO experts to maximize its impact.\nSupport vector machines have also been adopted for remote sensing tasks. Yan and Huang [@-yanDetectingSeaIce2019], for example, apply SVMs to detect sea ice, arguing that they provide better accuracy than maximum likelihood classification. A key advantage highlighted was the model’s robustness with limited training data. The study was particularly interesting because it addressed a gap in the application of SVMs to sea ice detection. Furthermore, the authors utilize Delay Doppler Mapping data from satellite TDS-1, a form of remote sensing data I hadn’t encountered before. They concluded that SVMs outperformed neural network (NN) and convolutional neural network (CNN) algorithms. While their analysis was not conducted in GEE, it still provided valuable insights into applying classification methods and working with new datasets.\nThese readings increased my appreciation for striking a balance between model complexity and interpretability. The more I explore EO applications, the more critically I can assess them. I found Svoboda et al. [@-svobodaRandomForestClassification2022] particularly effective in clearly outlining their policy objectives, tools, and methods, making the study easy to follow. In contrast, the second paper was less straightforward in connecting its findings to broader applications. I believe the most valuable research not only presents methodological advancements but also links them to actionable outcomes, ensuring their relevance beyond academic contexts.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nDuring the lecture this week, we skipped over the maximum likelihood portion of the presentation. It was mentioned that, these days, machine learning is more relevant. This made me wonder, are there still contexts where maximum likelihood remains useful? While ML approaches dominate, it’s important to remember that no model is universally superior.\nWhile I read the papers above, I was reminded that even sophisticated ML models are not infallible. For instance, the Czechia study showed lower accuracy for urban areas, demonstrating that advanced methods still struggle with certain classifications. As ML continues to shape classification tasks, researchers and practitioners must remain aware of its limitations, ensuring results are taken with caution rather than assumed to be inherently superior. This also links back to interpretability. While methods like random forests and SVMs may offer higher accuracy, their complexity can make them difficult to interpret. This trade-off between performance and transparency is crucial, particularly in contexts where decisions in analysis must be explainable to stakeholders.\nWith artificial intelligence now a major topic of discussion across many fields, this week’s content also led me to wonder how advanced AI and remote sensing might evolve together, and how the classification methods we are learning today will adapt. In a similar way that machine learning methods pose interpretability issues, AI-based approaches often function “black boxes” with decision-making processes that are difficult to trace. As AI inevitably weaves its way the way researchers conduct geospatial analysis, it will be critical to carry forward the lessons learned from ML challenges, particularly regarding model transparency and bias in training data.\nOne of the key takeaways for me from this week’s content is that high accuracy alone is not enough. Methods should be interpretable, reproducible, and applicable to real-world scenarios.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "8  SAR",
    "section": "",
    "text": "8.1 Summary\nIn our last lecture, we shifted focus to SAR (Synthetic Aperture Radar), an active sensor system that differs from the passive satellites we’ve learned about so far. Unlike passive sensors that rely on reflected sunlight, SAR actively emits electromagnetic signals and records the backscatter.\nWe first covered some key SAR concepts, including the difference between photographic and radar apertures. In optical imaging, a photographic aperture refers to the opening in a camera lens that controls the amount of light entering. In radar, however, “aperture” refers to the antenna’s effective size. A longer antenna produces a narrower radar beam, which improves spatial resolution. Since physically long antennas are impractical for spaceborne sensors, SAR simulates a larger antenna by capturing multiple backscatter signals as the sensor moves along its flight path. This technique effectively increases resolution, allowing SAR to capture fine-scale surface details.\nDifferent SAR polarizations help distinguish between various surface types. Vertical-vertical (VV) polarization is most effective for detecting surface roughness, while vertical-horizontal (VH) polarization is better suited for analyzing volume scatterers like vegetation. Double-bounce reflections, where radar waves bounce between two surfaces (e.g., buildings and the ground), can also be identified, making SAR a useful tool for mapping urban environments. Figure 1 illustrates these SAR fundamentals.\nSAR data types and techniques can be applied to different purposes. SAR data is presented in three forms: Power scale for statistical analysis, amplitude scale for visualization and dB scale for detecting differences in backscatter intensity. A common application of SAR is change-detection, which can be achieved through image subtraction or ratio-based techniques (e.g., mean and log ratios), paired with statistical methods like t-tests to identify significant differences. Image fusion at the decision-, obect-, or pixel-level can also be employed. SAR is effective for generating Digital Elevation Models (DEMs) as well. Interferometric SAR (InSAR) is a technique that leverages phase differences between two SAR images taken at different times or from slightly different angles to generate DEMs. Differential InSAR (DInSAR), meanwhile, extends this method to detect surface changes over time, allowing for precise analysis of land movement.\nDuring the practical session, we applied SAR techniques by working through Ollie Ballinger’s analysis of the Beirut explosion. An adapted pixelwise t-test was used to detect changes between pre- and post-explosion SAR data, revealing damage to built infrastructure. The results (Figure 2) highlighted SAR’s unique ability to detect change in environments.\nA recurring theme throughout this week, and this module, has been the importance of choosing the right method for the research question at hand. Its critical to think carefully about the problem and work backwards from there. Learning about SAR revealed entirely new possibilities for analysis using remote sensing but reinforced this idea that all methods have strengths and limitations which must be carefully considered.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>SAR</span>"
    ]
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  SAR",
    "section": "",
    "text": "Figure 1. SAR Basics. Source: NEC.\n\n\n\n\n\n\n\nFigure 2. Surface change in Beirut post-explosion, yellow areas indicate a significant change at the 95% confidence level.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>SAR</span>"
    ]
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "8  SAR",
    "section": "8.2 Application",
    "text": "8.2 Application\nSAR has a wide range of applications across various fields. I found a categorization by Tsokas et al. (2022) particularly useful for understanding its diverse uses:\n\nMapping & Land Classification: including land cover classification, forest monitoring, shellfish and oil spill detection, sea ice, and glaciers.\nParameter Retrieval: including ocean topography, wind and wave retrieval, and soil moisture estimation.\nObject Detection: including object detection and recognition, as well as navigation.\n\nWith regard to object detection, one application I found particularly interesting is the use of SAR for detecting ships. In their study, Zhang et al. (2021) review the use of the SAR Ship Detection Dataset (SSDD) for deep learning-based SAR ship detection. SSDD is an open dataset produced by one of the authors and includes SAR images with varying resolutions, polarizations, and surface conditions. The authors discuss the dataset’s widespread adoption but also acknowledge enduring challenges and areas for improvement. To me, this paper highlighted the value of open data and collaboration for advancing the field more broadly. I respect that, while the authors emphasized the uptake in use of their dataset, they are also cognizant and transparent about its limitations. This paper also underscored SAR’s versatility and practical application, particularly in terms of maritime traffic control, trade monitoring, and naval defense.\nAnother SAR application that stood out to me was wetland monitoring, as explored by Adeli et al. (2020). Wetlands provide essential ecosystem services but face increasing threats from human activity and climate change. The authors highlight how SAR is well-suited for wetland analysis because it can detect variations in surface roughness and moisture content, capabilities that are challenging for other remote sensing sources. The study conducts a meta-analysis of 172 papers, revealing trends such as the growing use of multi-sensor SAR data and the integration of C- and L-band frequencies, which improve classification accuracy. However, challenges remain, including backscatter similarity between different wetland types, difficulties in selecting the optimal SAR specifications (e.g., incidence angle, frequency, and polarization), and geometric distortions in SAR imagery. The authors emphasize the need for further research to address these issues and maximize SAR’s effectiveness in wetland monitoring and environmental change detection.\nSAR’s unique capabilities make it potentially better suited for certain analyses than the passive sensors we’ve learned about and worked with in previous weeks. These papers demonstrate how SAR can be applied to diverse issues, enabling more effective land management, trade monitoring, and security measures by providing detailed surface insights. SAR’s ability to capture data regardless of weather conditions or time of day makes it an invaluable tool for continuous monitoring and rapid response applications.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>SAR</span>"
    ]
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "8  SAR",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nIt was interesting to learn about a new satellite type this week and explore the different applications that come with it. SAR offers several advantages, such as its ability to penetrate cloud cover and capture surface texture at a high resolution. Being able to collect data in all weather conditions makes it particularly useful in circumstances where frequent and continuous monitoring is necessary. SAR also, however, comes with limitations. The data can be complex to process and interpret, perhaps less intuitive than dealing with passive sensors.\nWhat struck me was the clear policy applications of SAR across a wide range of fields. In defense, SAR-based object detection can enhance surveillance and border security, providing critical intelligence that would be difficult to obtain with passive sensors alone. In trade, SAR can play a key role in monitoring maritime traffic, tracking illegal fishing activities, and overseeing port operations. For environmental change, it offers powerful methods for tracking issues such as deforestation, wetland loss, glacial retreat, and urban expansion. Altogether, SAR presents a great opportunity to create new evidence bases on which decision-making and policy can be built.\nSince this is my last diary entry, I’ve been reflecting more broadly on everything we’ve covered through the term. The range of satellites, methods, and applications we’ve explored has been both impressive and inspiring. Remote sensing offers powerful tools to address a vast array of issues like urban planning, environmental conservation, public health, economic development and conflict, just to name a few. There are so many different ways to use these technologies to manage our cities and natural environments for the better.\nThe key challenge, however, is choosing the right data and methods for the research question at hand. And I would argue this task can be just as difficult as conducting the analysis itself. With so many data sources, analytical techniques, and even methods for validating other methods, it’s crucial to think carefully about the problem and select the approach that best fits the specific context. While the vast amount of available data and analytical possibilities is exciting, it can also feel overwhelming. Being precise with the research question and critically assessing the best way to approach it is essential.\nUltimately, remote sensing is not just a technical exercise, but also requires deep reflection. The best way to ensure meaningful results, strong research, and real-world project success is to be deliberate about data selection, methodology, and interpretation.\n\n\n\n\nAdeli, Sarina, Bahram Salehi, Masoud Mahdianpari, Lindi J. Quackenbush, Brian Brisco, Haifa Tamiminia, and Stephen Shaw. 2020. “Wetland Monitoring Using SAR Data: A Meta-Analysis and Comprehensive Review.” Remote Sensing 12 (14, 14): 2190. https://doi.org/10.3390/rs12142190.\n\n\nTsokas, Arsenios, Maciej Rysz, Panos M. Pardalos, and Kathleen Dipple. 2022. “SAR Data Applications in Earth Observation: An Overview.” Expert Systems with Applications 205 (November): 117342. https://doi.org/10.1016/j.eswa.2022.117342.\n\n\nZhang, Tianwen, Xiaoling Zhang, Jianwei Li, Xiaowo Xu, Baoyou Wang, Xu Zhan, Yanqin Xu, et al. 2021. “SAR Ship Detection Dataset (SSDD): Official Release and Comprehensive Data Analysis.” Remote Sensing 13 (18, 18): 3690. https://doi.org/10.3390/rs13183690.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>SAR</span>"
    ]
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  Classiciation II",
    "section": "",
    "text": "7.1 Summary\nThis week, we had our second lecture covering classification. We first looked at some pre-classified data sources to consider their advantages and limitations. One example discussed was Dynamic World, which provides near real-time, 10m resolution classifications (Figure 1). The major benefit here is the updating estimation of a range of land classes for the entire globe, including tree cover, snow coverage and urban areas. However, its reliance on training data from a single period means that it may struggle with seasonal variations, atmospheric conditions, and regional differences in land cover.\nBecause of these limitations, Dynamic World is more suitable for large-scale monitoring rather than local analyses requiring high precision. A key takeaway was that while pre-classified data sources can significantly reduce processing time, their accuracy and applicability must always be evaluated based on the specific research context.\nWe then examined alternative classification methods, including Object-Based Image Analysis (OBIA) and sub-pixel analysis, both of which address limitations of a pixel-based scale. OBIA groups neighboring pixels into objects based on spectral and textural similarities, which helps to reduce noise and improve classification accuracy. Sub-pixel analysis, on the other hand, allows for a more detailed breakdown of mixed pixels by assigning proportions of different land cover types within each pixel. This is especially useful in urban environments where impervious surfaces, vegetation, and bare land often co-exist within a single pixel.\nThe lecture also covered accuracy assessment, focusing on producer accuracy vs. user accuracy, which often trade off against each other. The F1 Score was introduced as a way to balance precision and recall, though it does not account for true negatives. The Kappa coefficient, a widely used metric in remote sensing, provides an overall measure of classification agreement but lacks a universally accepted threshold for what constitutes a “good” value. One critical issue with traditional validation approaches is spatial autocorrelation. When training and test samples are geographically close, model accuracy can be artificially inflated. Addressing this requires methods such as spatial cross-validation, which ensures that training and test data are spatially separated.\nIn the practical session, we applied a CART classifier to Dar Es Salaam’s land cover (Figure 2).\nComparing the results with my coursemate Chris revealed how the choice of training pixels impacts classification outcomes (Figure 3).\nDespite using the same method, our classifications significantly vary, highlighting that classification is not just a technical process but requires analyst judgment. To me, this reinforced the importance of carefully selecting training data.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classiciation II</span>"
    ]
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Classiciation II",
    "section": "",
    "text": "Figure 1. Dynamic World land cover classification of London.\n\n\n\n\n\n\n\n\n\nFigure 2. Output of CART classification of Dar Es Salaam, highlighting built-up areas forest, and bare earth.\n\n\n\n\n\n\nFigure 3. Chris’s CART classification of Dar Es Salaam, highlighting built-up areas forest, and bare earth.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classiciation II</span>"
    ]
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "7  Classiciation II",
    "section": "7.2 Application",
    "text": "7.2 Application\nAfter the lecture, I wanted to explore how researchers have applied these classification techniques, particularly sub-pixel analysis and OBIA, in real-world studies.\n\n7.2.1 Sub-Pixel Analysis\nResearch by Hu et al. (2017) investigates sub-pixel impervious surface percentage (SPIS), quantifying the fraction of impervious surfaces within each pixel. Using a CART-based model, the study integrated multi-seasonal satellite imagery and nighttime light (NTL) data to improve classification accuracy in Beijing. The inclusion of NTL data was particularly effective in distinguishing impervious surfaces from bare land, reducing misclassification errors. The study also conducted multi-temporal SPIS mapping from 1991 to 2016, highlighting urban expansion over time.\nAn key insight was the importance of multi-source data integration in enhancing classification performance. The study also acknowledged spatial autocorrelation, noting that splitting reference points by pixel block rather than individual pixels can help mitigate its effects. However, it did not delve deeper into how much this reduced spatial dependence or validate its effectiveness, which raises questions about the extent of autocorrelation still present in their results. Given our discussions on validation issues, it would have been useful if the study had explicitly measured how spatial autocorrelation affected model accuracy.\n\n\n7.2.2 OBIA\nScaling up past pixels, Cechim Junior et al. (2023) apply OBIA and machine learning to classify natural forests and plantation forests in Paraná, Brazil—two land cover types that are often misclassified due to their similar spectral signatures. By incorporating texture-based segmentation and spectral mixture analysis (SMA), the study purportedly achieved 96% accuracy, with a Kappa Index of 0.94. The analysis was performed on Google Earth Engine (GEE), allowing for efficient large-scale processing of Sentinel-2 imagery.\nOne concern that stood out to me was the use of the Kappa coefficient as a validation metric. As we discussed in class, Kappa is widely used but lacks a clear consensus on what constitutes a “good” result, making it difficult to compare across studies. Despite this, I appreciate that the authors followed principles of open and reproducible science, making their dataset and code publicly available on GitHub. This aligns with best practices we’ve discussed in ensuring transparency and replicability in remote sensing research.\n\n\n7.2.3 Thoughts\nChoosing a classification method should be guided by the specific problem at hand. Sub-pixel analysis is particularly useful for urban environments, where land cover types often mix within a single pixel, whereas OBIA is better suited for complex landscapes where texture and shape are key differentiators.\nIt was also interesting to see that only Hu et al. (2017) explicitly mentioned spatial autocorrelation, even though it remains a critical issue in classification accuracy. The fact that they only briefly addressed it, without actually testing the extent of its impact, reinforces the need for more attention to this when validating methods in classification studies.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classiciation II</span>"
    ]
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "7  Classiciation II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThis week’s material reinforced the policy significance of land cover classification in both urban and rural contexts. Different methods are particularly useful in different settings. For example, sub-pixel analysis is well-suited to dense, built-up areas, while OBIA performs better in rural landscapes where land cover types are more homogeneous. Choosing the right approach is crucial, as the accuracy of these classifications can directly impact policy related to urban planning, environmental management, conservation and more.\nOne of the key challenges discussed was validation. While the Kappa coefficient is widely used, there is no clear agreement on what constitutes a “good” value, making it difficult to compare results across studies. As we saw in class, the ROC curve, which accounts for true negatives, could offer a more comprehensive evaluation. That being said, it appears to be underutilized in remote sensing research. This raises the question of whether alternative validation methods should be more widely adopted.\nAnother critical issue is spatial autocorrelation. Hu et al. (2017) explicitly addressed it, noting that importance of separating training and test samples to reduce spatial dependencies. However, Cechim Junior et al. (2023) do not mention it, despite the potential for spatial bias in their classification results. This omission highlights a broader concern in land cover research: if spatial dependencies are ignored, models may appear more accurate than they actually are. Given that classification outputs inform policy and resource allocation, such errors can have real-world consequences, from misdirected conservation efforts to inefficient land use policies.\nReflecting on these studies, I was struck by how classification errors could adversely impact proper decision-making. If models are not rigorously validated, there is a real risk of misguided policy interventions based on flawed data. For instance, an underestimation of deforestation could slow conservation responses. This reinforces the need for critical evaluation of classification methods, validation techniques, and the spatial patterns that influence model performance.\n\n\n\n\nCechim Junior, Clovis, Araki Hideo, and Rodrigo and de Campos Macedo. 2023. “Object-Based Image Analysis (OBIA) and Machine Learning (ML) Applied to Tropical Forest Mapping Using Sentinel-2.” Canadian Journal of Remote Sensing 49 (1): 2259504. https://doi.org/10.1080/07038992.2023.2259504.\n\n\nHu, Deyong, Shanshan Chen, Kun Qiao, and Shisong Cao. 2017. “Integrating CART Algorithm and Multi-Source Remote Sensing Data to Estimate Sub-Pixel Impervious Surface Coverage: A Case Study from Beijing Municipality, China.” Chinese Geographical Science 27 (4): 614–25. https://doi.org/10.1007/s11769-017-0882-x.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classiciation II</span>"
    ]
  }
]